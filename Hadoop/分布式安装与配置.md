## 分布式安装与配置

​		与单机模式不同，分布式中的不同角色常常分配到不同的节点上，以便为不同性能的硬件分配不同的职责。

* Master：如namenode和resourcemanager常常在不同的节点上作为master集群；
* Slaves：datanode和nodemanager常常在一台机器，这些机器作为slave集群；
* Web UI：而其他服务Web App Proxy Server和MapReduce Job History server则可以根据情况放在共同的节点或分开配置，这取决于负载；

#### 1、运行平台

* Linux或windows

#### 2、必需软件

* jdk1.8
* hadoop2.8.4
* ssh

#### 3、配置

​		在hadoop集群中有多个守护进程：（HDFS）namenode、datanode、secondary namenode、（YARN）resourcemanager、nodemanager、webappproxy、（MapReduce）MapReduce Job HistoryServer。

##### 3.1 环境配置

​		守护进程的运行环境的配置，主要是hadoop-env.sh、yarn-env.sh、mapred-env.sh。最低限度的配置：至少要配置JAVA_HOME。

##### 3.2 守护进程的配置及相关参数说明

​		进程的相关参数可以直接配置到~/.bashrc或/etc/profile的环境变量中。

| DAEMON                        | Environment Variable                                         |
| ----------------------------- | ------------------------------------------------------------ |
| NameNode                      | HADOOP_NAMENODE_OPTS                                         |
| DataNode                      | HADOOP_DATANODE_OPTS                                         |
| Secondary NameNode            | HADOOP_SECONDARYNAMENODE_OPTS                                |
| ResourceManager               | YARN_RESOURCEMANAGER_OPTS、YARN_RESOURCEMANAGER_HEAPSIZE     |
| NodeManager                   | YARN_NODEMANAGER_OPTS、YARN_NODEMANAGER_HEAPSIZE             |
| WebAppProxy                   | YARN_PROXYSERVER_OPTS、YARN_PROXYSERVER_HEAPSIZE             |
| Map Reduce Job History Server | HADOOP_JOB_HISTORYSERVER_OPTS、HADOOP_JOB_HISTORYSERVER_HEAPSIZE |

如，想让namenode使用parallelGC，可以在hadoop-env.sh中配置：

```shell
export HADOOP_NAMENODE_OPTS="-XX:+UseParallelGC"   # 配置的其实是JVM
```

> 其他比较重要的几个参数：
>
> * HADOOP_PID_DIR：守护进程的id文件存储路径；
> * HADOOP_LOG_DIR：守护进程的日志文件的存储路径；
> * HADOOP_HEAPSIZE/YARN_HEAPSIZE：默认为1000MB，主要是分配守护进程的内存大小。
> * 
>
> *** 其中HADOOP_PID_DIR和HADOOP_LOG_DIR配置到运维人员才能有权限访问的目录，如果任何人都能访问，就有被恶意篡改的风险；

##### 3.3 <font color=red>重要配置明细</font>

* core-site.xml：

  ```shell
  <configuration>
  	<property>
  		<name>fs.defaultFS</name>
  		<value>hdfs://host:port</value>   # namenode的URI
  	</property>
  	<property>
  		<name>io.file.buffer.size</name>
  		<value>131072</value>			  # 读写seq文件时的缓存
  	</property>
  </configuration>
  ```

  

* hdfs-site.xml：

  * namenode的配置：

    ```shell
    <configuration>
    	<property>
    		<name>dfs.namenode.name.dir</name>
    		<value>~/hadoop/namenode</value>   # namenode用来存储namespace和交互记录的目录，可以配置多个（备份）
    	</property>
    	<property>
    		<name>dfs.hosts.exclude</name>
    		<value>slaveN</value>			  # 排除的datanode
    	</property>
    	<property>
    		<name>dfs.hosts</name>
    		<value>slaveN</value>			  # 指定相关的datanode
    	</property>
    	<property>
    		<name>dfs.blocksize</name>
    		<value>26843546</value>			  # 如果存大文件，就用256MB
    	</property>
    	<property>
    		<name>dfs.namenode.handler.count</name>
    		<value>100</value>			  # namenode处理RPC请求的线程数，即namenode的并发量。
    	</property>
    </configuration>
    ```

  * datanode的配置：

    ```shell
    <configuration>
    	<property>
    		<name>dfs.datanode.data.dir</name>
    		<value>~/hadoop/datanode</value>   # datanode的存block的目录，可以为多个目录。
    	</property>
    </configuration>
    ```

* yarn-site.xml：

  ```shell
  <configuration>
  	<property>
  		<name>yarn.acl.enable</name>
  		<value>true/false</value>   # 默认是False，是否允许ACLs
  	</property>
  	<property>
  		<name>yarn.admin.acl</name>
  		<value>Admin ACL</value>   # 默认是*(所有人)，空格表示拒绝所有人；可以设置多个组访问
  	</property>
  	<property>
  		<name>yarn.log-aggregation-enable</name>
  		<value>true/false</value>   # 聚集日志
  	</property>
  </configuration>
  ```

* slaves：

```shell
hostname1或ip1
hostname2或ip2
……
```

>  需配置免密或其他的方式（Kerberos）的身份认证。

##### 3.4 其他参数说明

所属文件：`yarn-site.xml`

ResourceManager：

| Parameter                                                    | Value                           | Notes                                                        |
| :----------------------------------------------------------- | :------------------------------ | :----------------------------------------------------------- |
| `yarn.resourcemanager.address`                               | 客户端用于提交任务的入口        | 会覆盖yarn.resourcemanager.hostname                          |
| `yarn.resourcemanager.scheduler.address`                     | 与调度器交互获取资源的入口      | 会覆盖yarn.resourcemanager.hostname                          |
| `yarn.resourcemanager.resource-tracker.address`              | 与NodeManager交互的入口         | 会覆盖yarn.resourcemanager.hostname                          |
| `yarn.resourcemanager.admin.address`                         | 接受管理指令的入口              | 会覆盖arn.resourcemanager.hostname                           |
| `yarn.resourcemanager.webapp.address`                        | Web UI                          | 会覆盖yarn.resourcemanager.hostname                          |
| `yarn.resourcemanager.hostname`                              | hostname                        | *host* Single hostname that can be set in place of setting all yarn.resourcemanager*address resources. Results in default ports for ResourceManager components. |
| `yarn.resourcemanager.scheduler.class`                       | 设置任务调度器                  | `CapacityScheduler` (recommended), `FairScheduler` (also recommended), or `FifoScheduler` |
| `yarn.scheduler.minimum-allocation-mb`                       | container的最小内存             | In MBs                                                       |
| `yarn.scheduler.maximum-allocation-mb`                       | container的最大内存             | In MBs                                                       |
| `yarn.resourcemanager.nodes.include-path` / `yarn.resourcemanager.nodes.exclude-path` | resourcemanager管理或排除的节点 | 管理NodeManager                                              |

NodeManager：

| Parameter                                    | Value                         | Notes                                                        |
| :------------------------------------------- | :---------------------------- | :----------------------------------------------------------- |
| `yarn.nodemanager.resource.memory-mb`        | 每个NodeManager分配的物理内存 | Nodemanager上用来启动container的内存总和。In MB              |
| `yarn.nodemanager.vmem-pmem-ratio`           | 使用虚拟内存与物理内存的比例  | In MB                                                        |
| `yarn.nodemanager.local-dirs`                | 可以有多个本地文件系统路径    | 主要是存储中间计算结果，帮助shuffle的磁盘IO                  |
| `yarn.nodemanager.log-dirs`                  | 可以有多个本地文件系统路径    | 如果设置多个路径，则多个路径都会存储日志文件，临时存储。     |
| `yarn.nodemanager.log.retain-seconds`        | *10800*                       | In seconds。NodeManager上保存日志文件的时长。 前提是没有使用聚集日志的配置。 |
| `yarn.nodemanager.remote-app-log-dir`        | */logs*                       | 这个是HDFS的目录，在任务结束后，相关任务日志存放的地方。最好设置相应的权限。该选项在聚集日志配置生效时有效。 |
| `yarn.nodemanager.remote-app-log-dir-suffix` | *logs*                        | Suffix appended to the remote log dir. Logs will be aggregated to ${yarn.nodemanager.remote-app-log-dir}/${user}/${thisParam} Only applicable if log-aggregation is enabled. |
| `yarn.nodemanager.aux-services`              | mapreduce_shuffle             | 给MapReduce应用的shuffle设置的                               |

History Server：

| Parameter                                            | Value | Notes                                                        |
| :--------------------------------------------------- | :---- | :----------------------------------------------------------- |
| `yarn.log-aggregation.retain-seconds`                | *-1*  | 保存聚集日志的时长. -1表示永久保存.该值不可设置的太小，否则会频繁请求namenode |
| `yarn.log-aggregation.retain-check-interval-seconds` | *-1*  | 检查日志寿命的心跳周期.如果置为小于等于0的数，则表示为aggregated log retention time的10分之一.太小同样会影响namenode的性能。 |

-----------------------------------------------------------------------------------------------------------------------

所属文件：`mapred-site.xml`

MapReduce：

| Parameter                                 | Value     | Notes                                                        |
| :---------------------------------------- | :-------- | :----------------------------------------------------------- |
| `mapreduce.framework.name`                | yarn      | hadoop的mapreduce执行框架                                    |
| `mapreduce.map.memory.mb`                 | 1536      | map任务的更高的存储限制 In MB                                |
| `mapreduce.map.java.opts`                 | -Xmx1024M | map中JVM的更高的资源限制                                     |
| `mapreduce.reduce.memory.mb`              | 3072      | reduce任务更高的的存储限制 In MB                             |
| `mapreduce.reduce.java.opts`              | -Xmx2560M | reduce中JVM的更高的资源限制                                  |
| `mapreduce.task.io.sort.mb`               | 512       | 排序时分配的内存                                             |
| `mapreduce.task.io.sort.factor`           | 100       | 排序时，合并到文件中的数据的量。（应该是数据溢出阶段的配置） |
| `mapreduce.reduce.shuffle.parallelcopies` | 50        | shuffle阶段，reduce从map输出拉取数据的并发度，表现为map的数量。 |

MapReduce JobHistory Server：

| Parameter                                    | Value             | Notes                                         |
| :------------------------------------------- | :---------------- | :-------------------------------------------- |
| `mapreduce.jobhistory.address`               | 服务host：port    | 默认端口为10020.                              |
| `mapreduce.jobhistory.webapp.address`        | Web UI的host:port | 默认端口为19888.                              |
| `mapreduce.jobhistory.intermediate-done-dir` | /mr-history/tmp   | MapReduce任务的日志目录                       |
| `mapreduce.jobhistory.done-dir`              | /mr-history/done  | MR JobHistory服务器管理的目录（已完成的任务） |

##### 3.5 诊断参数

​		Hadoop提供了NodeManager的健康诊断机制。运维人员可以提供自定义的脚本，当检测到非健康项时，可以在脚本中输出“ERROR”字符串，ResouceManager会根据是否检测到"ERROR"来当以NodeManager的状态。由此决定是否将节点列入黑名单（进入黑名单的节点将不会再被用于分配container）。相关参数在yarn-site.xml中配置：

| Parameter                                           | Value                               | Notes            |
| :-------------------------------------------------- | :---------------------------------- | :--------------- |
| `yarn.nodemanager.health-checker.script.path`       | Node health script                  | 脚本的路径       |
| `yarn.nodemanager.health-checker.script.opts`       | Node health script options          | 脚本检测的项     |
| `yarn.nodemanager.health-checker.interval-ms`       | Node health script interval         | 脚本检测时间间隔 |
| `yarn.nodemanager.health-checker.script.timeout-ms` | Node health script timeout interval | 超时时长         |

> 这种方法不应该用于检测本地磁盘故障

##### 3.6 机架感知

​		Hadoop中通过机架感知来保证性能和安全性，相关的配置（待续）建议自定义。

##### 3.7 日志配置

​		Hadoop采用Apache log4j，基于Apache Commons Logging框架来配置日志。

最后，将修改的配置分发到每个集群节点。

#### 4、启动集群



